{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb180bb",
   "metadata": {},
   "source": [
    "## Customer churn prediction\n",
    "\n",
    "#### Dataset description\n",
    "- This dataset is randomly collected from an Iranian telecom company database over a period of 12 months. \n",
    "- A total of 3150 rows of data, each representing a customer, bear information for 13 columns.\n",
    "\n",
    "\n",
    "#### Columns description\n",
    "- **Call Failures**: number of call failures\n",
    "- **Complains**: binary (0: No complaint, 1: complaint)\n",
    "- **Subscription**: Length: total months of subscription\n",
    "- **Charge Amount**: Ordinal attribute (0: lowest amount, 9: highest amount)\n",
    "- **Seconds of Use**: total seconds of calls\n",
    "- **Frequency of use**: total number of calls\n",
    "- **Frequency of SMS**: total number of text messages\n",
    "- **Distinct Called Numbers**: total number of distinct phone calls \n",
    "- **Age Group**: ordinal attribute (1: younger age, 5: older age)\n",
    "- **Tariff Plan**: binary (1: Pay as you go, 2: contractual)\n",
    "- **Status**: binary (1: active, 2: non-active)\n",
    "- **Churn**: binary (1: churn, 0: non-churn)\n",
    "- **Customer Value**: The calculated value of customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e7641-a547-433f-8f0c-66049a48548a",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e312f0-93aa-4be3-8275-7ea2a9e1f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split,  GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff5b6f",
   "metadata": {},
   "source": [
    "#### Declaring constants / Project config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e9862-6bab-49ae-b4d1-976f67c7cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = './input/'\n",
    "OUTPUT_PATH = './output/'\n",
    "\n",
    "INPUT_FILENAME = 'raw.csv'\n",
    "\n",
    "LABELS_DICT = {\n",
    "    'call_failure': 'Call Failure',\n",
    "    'complains': 'Complains',\n",
    "    'subscription_length': 'Subscription Length',\n",
    "    'charge_amount': 'Charge Amount',\n",
    "    'seconds_of_use': 'Seconds of Use',\n",
    "    'frequency_of_use': 'Frequency of Use',\n",
    "    'frequency_of_sms': 'Frequency of SMS',\n",
    "    'distinct_called_numbers': 'Distinct Called Numbers',\n",
    "    'age_group': 'Age Group',\n",
    "    'tariff_plan': 'Tariff Plan',\n",
    "    'status': 'Status',\n",
    "    'age': 'Age',\n",
    "    'customer_value': 'Customer Value',\n",
    "    'churn': 'Churn'\n",
    "}\n",
    "\n",
    "target_col = 'churn'\n",
    "\n",
    "px.defaults.template = 'plotly_dark'\n",
    "\n",
    "# pio.renderers.default = \"notebook\" \n",
    "\n",
    "# za graph preview na Github-u\n",
    "png_renderer = pio.renderers[\"png\"]\n",
    "png_renderer.width = 1400\n",
    "png_renderer.height = 500\n",
    "pio.renderers.default = \"png\" \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171b236c-414e-439a-9804-847001437539",
   "metadata": {},
   "source": [
    "#### Reading input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93db4d-b71e-4426-8e0a-d907f0dd6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_PATH + INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf64f01-09a8-4d41-974f-950c846a5358",
   "metadata": {},
   "source": [
    "#### Previewing data attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c97647-c2e4-464e-9af5-5e06a2d5eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b16cbe-5804-4ae8-a9b4-fc3a5c1aa77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e5401-5cee-4f82-8527-da801c746b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df356979-c92a-4af9-8079-16ce7a88b942",
   "metadata": {},
   "source": [
    "#### Profiling data (ydata_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848983a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "\n",
    "# profile.to_file(f'{OUTPUT_PATH}profiling_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5b412-fb10-407b-b878-0a78c6899d15",
   "metadata": {},
   "source": [
    "#### Renaming columns to snake case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da039d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('__', '_')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df1c45",
   "metadata": {},
   "source": [
    "#### Data visualization and descriptive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hist(columns):\n",
    "    fig = make_subplots(rows=math.ceil(len(columns) / 2), cols=2)\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        row = i // 2 + 1  \n",
    "        col_num = i % 2 + 1 \n",
    "        fig.add_histogram(x=df[col], row=row, col=col_num, name=col)\n",
    "\n",
    "        fig.update_xaxes(title_text=LABELS_DICT[col], row=row, col=col_num)\n",
    "        fig.update_yaxes(title_text='Frequency', row=row, col=col_num)\n",
    "\n",
    "    fig.update_layout(height=1400, showlegend=False, template='plotly_dark', title_text=\"Histograms of Columns\")\n",
    "    fig.show(renderer=\"png\", width=1400, height=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bcb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualize_hist(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a09a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.scatter(df, \n",
    "                 x='subscription_length', \n",
    "                 y='charge_amount', \n",
    "                 color='churn', \n",
    "                 size='charge_amount',\n",
    "                 hover_data=['subscription_length'],\n",
    "                 title='Charge Amount Over Subscription Length with Churn',\n",
    "                 labels=LABELS_DICT)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(df,\n",
    "                x='seconds_of_use',\n",
    "                y='frequency_of_use',\n",
    "                color='churn',\n",
    "                labels=LABELS_DICT,\n",
    "                title='Usage vs Frequency')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(df,\n",
    "                    x='customer_value',\n",
    "                    color='churn',\n",
    "                    labels=LABELS_DICT,\n",
    "                    title='Customer value distribution')\n",
    "fig.show()\n",
    "\n",
    "fig = px.box(df, \n",
    "            x='age_group', \n",
    "            y='subscription_length', \n",
    "            labels=LABELS_DICT,\n",
    "            points='all', \n",
    "            title='Subscription Length by Age Group')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "fig = px.imshow(correlation_matrix,\n",
    "                labels=LABELS_DICT,\n",
    "                x=correlation_matrix.index,\n",
    "                y=correlation_matrix.columns,\n",
    "                height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87e7d04",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79670033",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['age']\n",
    "df = df.drop(columns=cols_to_drop, index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50459021",
   "metadata": {},
   "source": [
    "#### Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().value_counts())\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bb25d",
   "metadata": {},
   "source": [
    "#### Removing outliers (IRQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['call_failure', 'subscription_length', 'charge_amount',\n",
    "                     'seconds_of_use', 'frequency_of_use', 'frequency_of_sms', 'distinct_called_numbers', 'customer_value']\n",
    "\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    data_no_outliers = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "    \n",
    "    return data_no_outliers\n",
    "\n",
    "for column in numerical_cols:\n",
    "    df = remove_outliers_iqr(df, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27e609",
   "metadata": {},
   "source": [
    "#### Feature scalling with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbee625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_cols] = MinMaxScaler().fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6cd84",
   "metadata": {},
   "source": [
    "##### Categorical encoding (One hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['complains', 'tariff_plan', 'status']\n",
    "\n",
    "df = pd.get_dummies(df, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6037303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5b4d8",
   "metadata": {},
   "source": [
    "##### Handling imbalanced classes (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75586772",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClass Distribution for 'churn' Column:\")\n",
    "print(df['churn'].value_counts())\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('over', SMOTE(sampling_strategy=0.5)),\n",
    "    ('under', RandomUnderSampler(sampling_strategy=1.0))\n",
    "])\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(df.drop(target_col, axis=1), df[target_col])\n",
    "df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "print(\"\\nClass Distribution for 'churn' column after SMOTE:\")\n",
    "print( df['churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae1fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942a280",
   "metadata": {},
   "source": [
    "#### Spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1f779c",
   "metadata": {},
   "source": [
    "#### Defining Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    {\n",
    "        'name': 'SVM',\n",
    "        'classifier': SVC(),\n",
    "        'param_grid': {\n",
    "            # 'classifier__C': [0.1, 1, 10], \n",
    "            # 'classifier__kernel': ['linear', 'rbf']\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'RandomForest',\n",
    "        'classifier': RandomForestClassifier(),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [50, 100, 200], \n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'regressor__min_samples_leaf': [2, 4, 8],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'LogisticRegression',\n",
    "        'classifier': LogisticRegression(),\n",
    "        'param_grid': {\n",
    "            # 'classifier__C': [0.1, 1, 10],\n",
    "            # 'classifier__penalty': ['l2'],\n",
    "            # 'classifier__max_iter': [1000],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'GradientBoosting',\n",
    "        'classifier': GradientBoostingClassifier(),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'classifier__max_depth': [3, 5, 7],\n",
    "            # 'regressor__min_samples_split': [2, 4, 8],\n",
    "            'regressor__min_samples_leaf': [2, 4, 8],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'KNeighbors',\n",
    "        'classifier': KNeighborsClassifier(),\n",
    "        'param_grid': {\n",
    "            # 'classifier__n_neighbors': [3, 5, 7],\n",
    "            # 'classifier__weights': ['uniform', 'distance'],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'DecisionTree',\n",
    "        'classifier': DecisionTreeClassifier(),\n",
    "        'param_grid': {\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [None, 5, 10],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'NaiveBayes',\n",
    "        'classifier': GaussianNB(),\n",
    "        'param_grid': {},\n",
    "    },\n",
    "    {\n",
    "        'name': 'AdaBoost',\n",
    "        'classifier': AdaBoostClassifier(),\n",
    "        'param_grid': {\n",
    "            # 'classifier__n_estimators': [50, 100, 200],\n",
    "            # 'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        },\n",
    "    },\n",
    "        {\n",
    "        'name': 'ExtraTrees',\n",
    "        'classifier': ExtraTreesClassifier(),\n",
    "        'param_grid': {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'regressor__min_samples_leaf': [2, 4, 8],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        'name': 'Bagging',\n",
    "        'classifier': BaggingClassifier(),\n",
    "        'param_grid': {\n",
    "            # 'classifier__n_estimators': [50, 100, 200],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a59c888",
   "metadata": {},
   "source": [
    "#### Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(classifier, X_train, X_test, y_train, y_test):\n",
    "    pipeline = Pipeline([\n",
    "        ('pca', PCA(n_components=10)), \n",
    "        ('classifier', classifier['classifier']),\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, classifier['param_grid'], cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{classifier['name']} Test Set Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "    result = {\n",
    "        'name': classifier['name'],\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'best_params': best_params,\n",
    "        'conf_matrix': confusion_matrix(y_test, y_pred),\n",
    "        'class_report': classification_report(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_results(results):\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values(by='test_accuracy', ascending=False)\n",
    "\n",
    "    fig = px.bar(\n",
    "        df_results, \n",
    "        x='test_accuracy', \n",
    "        y='name', \n",
    "        orientation='h', \n",
    "        title='Test set accuracy of different classifiers',\n",
    "        color='name',\n",
    "        labels={'name': 'Classifier'}\n",
    "    )\n",
    "\n",
    "    fig.update_layout(xaxis_title='Test Set Accuracy', yaxis_title='Classifier')\n",
    "    fig.show()\n",
    "\n",
    "best_overall_model_name = None\n",
    "best_overall_accuracy = 0.0\n",
    "results = []\n",
    "\n",
    "with open(f'{OUTPUT_PATH}model_eval_results.txt', 'w') as file:\n",
    "    for classifier in classifiers:\n",
    "        file.write(f\"Training and evaluating {classifier['name']}...\\n\")\n",
    "        result = train_evaluate_model(classifier, X_train, X_test, y_train, y_test)\n",
    "        results.append(result)\n",
    "\n",
    "        if result['test_accuracy'] > best_overall_accuracy:\n",
    "            best_overall_model_name = classifier['name']\n",
    "            best_overall_accuracy = result['test_accuracy']\n",
    "\n",
    "        file.write(f\"{classifier['name']} Confusion Matrix:\\n{result['conf_matrix']}\\n\")\n",
    "        file.write(f\"{classifier['name']} Classification Report:\\n{result['class_report']}\\n\")\n",
    "        file.write(f\"Best hyperparameters: {result['best_params']}\\n\")\n",
    "        file.write(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "best_model_result = next(item for item in results if item[\"name\"] == best_overall_model_name)\n",
    "\n",
    "print(\"\\nOverall best model:\")\n",
    "print(f\"Model: {best_overall_model_name}\")\n",
    "print(f\"Test Set Accuracy: {best_overall_accuracy*100:.2f}%\")\n",
    "\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f88fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_results = [result for result in results if result['name'] == best_overall_model_name][0]\n",
    "best_model_params = best_model_results['best_params']\n",
    "best_classifier = next((classifier for classifier in classifiers if classifier['name'] == best_overall_model_name), None)\n",
    "\n",
    "if not best_classifier:\n",
    "    print(f\"No information found for the best overall model: {best_overall_model_name}\")\n",
    "    exit()\n",
    "\n",
    "classifier_params = {key.replace('classifier__', ''): value for key, value in best_model_params.items() if key.startswith('classifier__')}\n",
    "\n",
    "best_model = best_classifier['classifier'].__class__(**classifier_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "nr_features_to_select = 12\n",
    "\n",
    "selector = RFE(best_model, n_features_to_select=nr_features_to_select, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "selected_features_mask = selector.support_\n",
    "selected_features = X_train.columns[selected_features_mask]\n",
    "\n",
    "k = nr_features_to_select \n",
    "\n",
    "top_features = selected_features[:k]\n",
    "top_rankings = selector.ranking_[:k]\n",
    "\n",
    "sorted_indices = sorted(range(len(top_rankings)), key=lambda k: top_rankings[k], reverse=True)\n",
    "top_features = [top_features[i] for i in sorted_indices]\n",
    "top_rankings = [top_rankings[i] for i in sorted_indices]\n",
    "\n",
    "fig_rfe = px.bar(\n",
    "    x=top_features,\n",
    "    y=top_rankings,\n",
    "    title=f'Recursive Feature Elimination (RFE) Ranking for {best_overall_model_name}',\n",
    ")\n",
    "\n",
    "fig_rfe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fa914",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "best_model.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Performance for {best_overall_model_name} with selected features:\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
